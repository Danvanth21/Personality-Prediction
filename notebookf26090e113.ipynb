{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport string\nimport pickle\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:29.624133Z","iopub.execute_input":"2021-11-02T12:57:29.624932Z","iopub.status.idle":"2021-11-02T12:57:31.095247Z","shell.execute_reply.started":"2021-11-02T12:57:29.624836Z","shell.execute_reply":"2021-11-02T12:57:31.094279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing tools\n\nps = PorterStemmer()\nwnl = WordNetLemmatizer()\nstr_punc = string.punctuation\n\nengstopwords = stopwords.words(\"english\")\nengstopwordsV2 = re.sub('[' + re.escape(string.punctuation) + ']', '',\n                        ' '.join(engstopwords)).split()\n\nengstopwords = set(engstopwords).union(set(engstopwordsV2))","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:31.299347Z","iopub.execute_input":"2021-11-02T12:57:31.299646Z","iopub.status.idle":"2021-11-02T12:57:31.311733Z","shell.execute_reply.started":"2021-11-02T12:57:31.299611Z","shell.execute_reply":"2021-11-02T12:57:31.310953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to lemmatize a word using the three types: adjective, verb, noun\ndef lemmatize_all_types(word):\n    word = wnl.lemmatize(word, 'a')\n    word = wnl.lemmatize(word, 'v')\n    word = wnl.lemmatize(word, 'n')\n    return word\n\n# Function to clean text\ndef clean(text):\n    # Remove URLs from text\n    text = re.sub(\"http.*?([ ]|\\|\\|\\||$)\", \"\", text).lower()\n    url_regex = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n    text = re.sub(url_regex, \"\", text)\n\n    # Remove specific punctuation (usually associated with a word)\n    text = re.sub(r'(:|;).', \" \", text)\n    \n    # Remove punctuations\n    text = re.sub('['+re.escape(str_punc)+']',\" \",  text)\n    \n    # Remove parantheses, brackets\n    text = re.sub('(\\[|\\()*\\d+(\\]|\\))*', ' ', text)\n    \n    # Remove string marks\n    text = re.sub('[’‘“\\.”…–]', '', text)\n    text = re.sub('[^(\\w|\\s)]', '', text)\n    text = re.sub('(gt|lt)', '', text)\n    \n    #Check that each word is not stopword, and lemmatize it\n    text = list(map(lemmatize_all_types, text.split()))\n    text = [word for word in text if (word not in engstopwords)]\n    text = \" \".join(text)\n    return text\n\n# Convert personality type into a dominant cognitive function\ndef letters_to_functions(personality_type):\n    translator = {\n            'ENxP': 'Ne',\n            'INxJ': 'Ni',\n            'ESxP': 'Se',\n            'ISxJ': 'Si',\n            'ExTJ': 'Te',\n            'IxTP': 'Ti',\n            'IxFP': 'Fi',\n            'ExFJ': 'Fe',\n            \n            'xNxx': 'N',\n            'xSxx': 'S',\n            'xxTx' : 'T',\n            'xxFx': 'F',\n            'Ixxx':'I',\n            'Exxx':'E',\n            }\n    return translator[personality_type]\n\n# Convert a Cognitive Functions Stack into Personality Type\ndef functions_to_letters(functions):\n    translator = {\n            'NiTe': 'INTJ',\n            'NiFe': 'INFJ',\n            'NeTi': 'ENTP',\n            'NeFi': 'ENFP',\n            'SiTe': 'ISTJ',\n            'SiFe': 'ISFJ',\n            'SeTi': 'ESTP',\n            'SeFi': 'ESFP',\n            'TeNi': 'ENTJ',\n            'FeNi': 'ENFJ',\n            'TiNe': 'INTP',\n            'FiNe': 'INFP',\n            'TeSi': 'ESTJ',\n            'FeSi': 'ESFJ',\n            'TiSe': 'ISTP',\n            'FiSe': 'ISFP',\n            }\n    return translator[functions]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:32.794369Z","iopub.execute_input":"2021-11-02T12:57:32.794824Z","iopub.status.idle":"2021-11-02T12:57:32.809929Z","shell.execute_reply.started":"2021-11-02T12:57:32.794777Z","shell.execute_reply":"2021-11-02T12:57:32.809123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cognitive Functions meta-information\ncf_info = {\n        \"Ni\": {\n                'name':'intuition',\n                'role':'input',\n                'direction':'internal'\n                },\n        \"Ne\": {\n                'name':'intuition',\n                'role':'input',\n                'direction':'external'\n                },\n        \"Si\": {\n                'name':'sensing',\n                'role':'input',\n                'direction':'internal'\n                },\n        \"Se\": {\n                'name':'sensing',\n                'role':'input',\n                'direction':'external'\n                },\n        'Ti': {\n                'name':'thinking',\n                'role':'output',\n                'direction':'internal'\n                },\n        'Te': {\n                'name':'thinking',\n                'role':'output',\n                'direction':'external'\n                },\n        'Fi': {\n                'name':'feeling',\n                'role':'output',\n                'direction':'internal',\n                },\n        'Fe': {\n                'name':'feeling',\n                'role':'output',\n                'direction':'external'\n                }\n        }\n\n# Dictionary of pretrained models\nmodels = {\n        # Phase 1 models\n        'NiNe':None,\n        'NiSi':None,\n        'NiSe':None,\n        'NeSi':None,\n        'NeSe':None,\n        'SiSe':None,\n        \n        'TiTe':None,\n        'TiFi':None,\n        'TiFe':None,\n        'TeFi':None,\n        'TeFe':None,\n        'FiFe':None,\n            \n        # Phase 2 models\n    \n        # Scenario 1 (detect dominant cognitive function)\n        'NiTe':None,\n        'NiFe':None,\n        'SiTe':None,\n        'SiFe':None,\n        \n        'NeFi':None,\n        'NeTi':None,\n        'SeFi':None,\n        'SeTi':None,\n        \n        # Secenario 2 (fixing phase 1 result corruption)\n        'NiTi':None,\n        'NiFi':None,\n        'NeTe':None,\n        'NeFe':None,\n        \n        'SiTi':None,\n        'SiFi':None,\n        'SeTe':None,\n        'SeFe':None,\n        }\n\n# Supporter pretrained models, increases accuracy ~3%\nsupporters = {\n        'NvS':None,\n        'FvT':None,\n        'IvE':None,\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:34.200004Z","iopub.execute_input":"2021-11-02T12:57:34.200334Z","iopub.status.idle":"2021-11-02T12:57:34.211955Z","shell.execute_reply.started":"2021-11-02T12:57:34.2003Z","shell.execute_reply":"2021-11-02T12:57:34.211003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read models\npath = \"../input/mbti-pretrained-models/\"\n\nfor key in models:\n    with open(path + key + '.pickle', 'rb') as file:\n        models[key] = pickle.load(file)\n\nfor _key in supporters:\n    with open(path + _key + '.pickle', 'rb') as file:\n        supporters[_key] = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:35.983791Z","iopub.execute_input":"2021-11-02T12:57:35.984368Z","iopub.status.idle":"2021-11-02T12:57:37.469192Z","shell.execute_reply.started":"2021-11-02T12:57:35.984316Z","shell.execute_reply":"2021-11-02T12:57:37.468418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the direction of a cognitive function (i => e | e => i)\ndef flip_cf_direction(cognitiveFunction):\n    direction = cognitiveFunction[1]\n    new_direction = 'i' if direction == 'e' else 'e'\n    return cognitiveFunction[0] + new_direction\n\n# Pipeline for using a pre-trained model to predict sample\ndef process_classify_sample(modelObject, sample):\n    vectorizer = modelObject['cv']\n    label_encoder = modelObject['labelEncoder']\n    model = modelObject['model']\n    \n    # Preprocessing\n    clean_sample = clean(sample)\n    x = vectorizer.transform([clean_sample]).toarray()\n    \n    # Classification\n    y = model.predict(x)\n    y_probability = max(model.predict_proba(x)[0])\n    classified_cf = label_encoder.inverse_transform(y)[0]\n    return letters_to_functions(classified_cf), y_probability\n\n    \n# Phase 1 of classifying a personality type\n# Recognize the top perceiving cognitive function\n# and the top judging cognitive function\ndef phase1(sample):\n    # INPUT => sample: string\n    # OUTPUT => input_cf_acc, output_cf_acc: Series \n\n    # Keep track of every input (perceiving) cognitive function likelihood\n    input_cf_acc = pd.Series({\"Ni\":0, \"Ne\":0, \"Si\":0, \"Se\":0}, dtype=float)\n    # same for output (judging) cognitive functions\n    output_cf_acc = pd.Series({\"Ti\":0, \"Te\":0, \"Fi\":0, \"Fe\":0}, dtype=float)\n    \n    input_cf = np.array(['Ni', 'Ne', 'Si', 'Se'])\n    output_cf = np.array(['Ti', 'Te', 'Fi', 'Fe'])\n    \n    # nested loop for input (perceiving) cognitive functions\n    # so models are: NiNe, NiSi, NiSe,  ...\n    for i in range(3):\n        for j in range(i+1, 4):\n            model_name = input_cf[i] + input_cf[j]\n            modelObject = models[model_name]\n            cognitive_fn, probability = process_classify_sample(modelObject, sample)\n            \n            # Incrase likelihood of the prediction class\n            input_cf_acc[cognitive_fn] += probability\n            other_cf = input_cf[i] if input_cf[j] == cognitive_fn else input_cf[j]\n            \n            # Increase likelihood (smaller value) of other classes\n            input_cf_acc[other_cf] += 1 - probability\n            \n    # Another nested loop for output (judging) cognitive functions\n    # so models are: TiTe, TiFi, TiFe, ...\n    for i in range(3):\n        for j in range(i+1, 4):\n            model_name = output_cf[i] + output_cf[j]\n            modelObject = models[model_name]\n            cognitive_fn, probability = process_classify_sample(modelObject, sample)\n            \n            # Incrase likelihood of the prediction class\n            output_cf_acc[cognitive_fn] += probability\n            other_cf = output_cf[i] if output_cf[j] == cognitive_fn else output_cf[j]\n            \n            # Increase likelihood (smaller value) of other classes\n            output_cf_acc[other_cf] += 1 - probability\n    \n    # Use supporter model (iNtuition vs Sensing)\n    modelObject = supporters[\"NvS\"]\n    cognitive_fn, probability = process_classify_sample(modelObject, sample)\n    \n    # Increase iNtuitive functions\n    if cognitive_fn == \"N\":\n        input_cf_acc[['Ni', 'Ne']] += probability\n        input_cf_acc[['Si', 'Se']] += 1 - probability\n    # Increase Sensing functions\n    else:\n        input_cf_acc[['Si', 'Se']] += probability\n        input_cf_acc[['Ni', 'Ne']] += 1 - probability\n    \n    # Use supporter model (Feeling vs Thinking)\n    modelObject = supporters[\"FvT\"]\n    cognitive_fn, probability = process_classify_sample(modelObject, sample)\n    \n    # Increase Feeling functions likelihood\n    if cognitive_fn == \"F\":\n        output_cf_acc[['Fi', 'Fe']] += probability\n        output_cf_acc[['Ti', 'Te']] += 1 - probability\n    # Increase Thinking Functions likelihood\n    else:\n        output_cf_acc[['Ti', 'Te']] += probability\n        output_cf_acc[['Fi', 'Fe']] += 1 - probability   \n    \n    # Use supporter model (Introvert vs Extrovert)\n    modelObject = supporters[\"IvE\"]\n    cognitive_fn, probability = process_classify_sample(modelObject, sample)\n    \n    # Increase Introverted functions likelihood\n    if cognitive_fn == \"I\":\n        input_cf_acc[['Ni', 'Si']] += probability\n        input_cf_acc[['Ne', 'Se']] += 1 - probability\n        \n        output_cf_acc[['Fi', 'Ti']] += probability\n        output_cf_acc[['Fe', 'Te']] += 1 - probability\n        \n    # Increase  Extroverted functions likelihood\n    else:\n        input_cf_acc[['Ne', 'Se']] += probability\n        input_cf_acc[['Ni', 'Si']] += 1 - probability\n        \n        output_cf_acc[['Fe', 'Te']] += probability\n        output_cf_acc[['Fi', 'Ti']] += 1 - probability\n    \n    # Return: likelihoods of perceiving (input) cognitive functions\n    # and judging (output) cogitive function\n    return input_cf_acc, output_cf_acc\n\n    \n    \n# Phase 2 of classification algorithm\n# Determine which cognitive function is the dominant\n# and which is the auxiliary.\n# and Fix the classification if necessary\n# Necessary: if phase 1 results a two cognitive functions\n# of the same direction (ex: Ni-Ti), this is not acceptable\n# since there's no personality with these Dom-Aux functions\ndef phase2(sample, input_acc, output_acc):\n    # Number of classifications done on every cognitive functions\n    # (i.e. we ran 5 models having 'Ni' as one of it's classes)\n    counter_models_ran = 5\n    \n    # Get max-likelihood data (probability & className)\n    # maxInput is the perceiving function which got the maximum likelihood\n    # maxOutput is the judgning function ~~~~~~\n    maxInput = {'name':input_acc.idxmax(), 'proba':input_acc.max()}\n    maxOutput = {'name':output_acc.idxmax(), 'proba':output_acc.max()}\n    \n    # Get direction of each cognitive function\n    maxInputDirection = cf_info[maxInput['name']]['direction']\n    maxOutputDirection = cf_info[maxOutput['name']]['direction']\n    \n    # Get the next models ready by concatenating cognitive functions (ie. 'NiTe')\n    cf_stack = np.array([input_acc.idxmax(), output_acc.idxmax()])\n    phase2_model_name = \"\".join(cf_stack)\n    \n    # if both perceiving & judging classes (functions) are opposite direction\n    if maxInputDirection != maxOutputDirection:\n        # We know the top two cognitive functions (ie. Ni, Te)\n        # this path will run the appropriate models to\n        # determine which of these functions is Dominant (primary)\n        # and which is Auxiliary (secondary)\n\n        # determine which cognitive_function is the dominant one\n        modelObject = models[phase2_model_name]\n        dominant_cf_name, probability = process_classify_sample(modelObject, sample)\n        counter_models_ran += 1\n        \n    # both perceiving & judging functions have same direction (they must NOT)\n    else:\n        # There is an ambiguity, the top 2 cognitive_functions cannot be of\n        # the same direction (ie. Ni, Ti) (they're both 'i')\n        # One of them is correct, this function will detect which one is\n        \n        # Detect which of these functions is more accurate\n        modelObject = models[phase2_model_name]\n        dominant_cf_name, probability = process_classify_sample(modelObject, sample)\n        counter_models_ran += 1\n        \n        \n        # if dominant cognitive function is an input (perceiving) \n        # (ie: Ni, Ne, Si, Se)\n        # flip the direction of the other -output- function\n        # example: Ni-Ti  => Ni-Te\n        if dominant_cf_name == input_acc.idxmax():\n            problematic_cf = output_acc.idxmax()\n            input_acc[input_acc.idxmax()] += probability\n            fixed_cf_name = flip_cf_direction(problematic_cf)\n            temp_acc = output_acc[fixed_cf_name]\n            output_acc[fixed_cf_name] = output_acc[problematic_cf] + (1 - probability)\n            output_acc[problematic_cf] = temp_acc\n        \n        # else if the dominant cognitive function is an output (judging)\n        # (ie: Ti, Te, Fi, Fe)\n        # flip the direction of the other -input- function\n        # example: Ni-Ti => Ne-Ti\n        else:\n            problematic_cf = input_acc.idxmax()\n            output_acc[output_acc.idxmax()] += probability\n            fixed_cf_name = flip_cf_direction(problematic_cf)\n            temp_acc = input_acc[fixed_cf_name]\n            input_acc[fixed_cf_name] = input_acc[problematic_cf] + (1 - probability)\n            input_acc[problematic_cf] = temp_acc\n        \n        # Now we've fixed the direction of the (less) accurate cognitive function\n        # We need to determine which function is dominant\n        \n        # Get the next models ready by concatenating cognitive functions (ie. 'NiTe')\n        cf_stack = np.array([input_acc.idxmax(), output_acc.idxmax()])\n        phase2_final_model_name = \"\".join(cf_stack)\n\n        # Run model\n        modelObject = models[phase2_final_model_name]\n        dominant_cf_name, probability = process_classify_sample(modelObject, sample)\n        counter_models_ran += 1\n    \n    # Now we know which cognitive function is dominant and which is auxilary.\n    # handle their likelihoods\n    \n    # If dominant function is input (perceiving)\n    # increase its likelihood, decrease the other\n    if dominant_cf_name == input_acc.idxmax():\n        input_acc[input_acc.idxmax()] += probability\n        output_acc[output_acc.idxmax()] += 1 - probability\n\n    # else, dominant function is output (judging)\n    # increase its likelihood, decrease the other\n    else:\n        output_acc[output_acc.idxmax()] += probability\n        input_acc[input_acc.idxmax()] += 1 - probability\n\n    # Select the winners in phase 1\n    cognitive_functions_stack = pd.Series({\n            input_acc.idxmax(): input_acc[input_acc.idxmax()],\n            output_acc.idxmax(): output_acc[output_acc.idxmax()]\n            })\n    \n    # Select the dominant function as the 1st winner in phase 2\n    dominant_function =  dominant_cf_name\n    \n    # Select the auxiliary function as the 2nd winner in phase 2\n    auxiliary_function = cognitive_functions_stack.drop(dominant_cf_name).index[0]\n\n    # Convert cognitive functions to personality types\n    personality_type = functions_to_letters(dominant_function + auxiliary_function)\n    \n    # Calculate probability\n    probability = (cognitive_functions_stack[dominant_function] / counter_models_ran \n                   + cognitive_functions_stack[auxiliary_function] / counter_models_ran) / 2\n    \n    return personality_type, probability\n\n# Run classification algorithm phases\ndef run(sample):\n    input_acc, output_acc = phase1(sample)\n    personality, probability = phase2(sample, input_acc, output_acc)\n    return personality, probability","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:37.512347Z","iopub.execute_input":"2021-11-02T12:57:37.512633Z","iopub.status.idle":"2021-11-02T12:57:37.744025Z","shell.execute_reply.started":"2021-11-02T12:57:37.512605Z","shell.execute_reply":"2021-11-02T12:57:37.743025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALIDATION\nvalidation_set = pd.read_csv(path + 'validation_set.csv')\n\ndef classify(sentence):\n    personality, probability = run(sentence)\n    return personality\n\n# Results as 16 personality types\ny_pred = validation_set['posts'].apply(classify) # it takes ~5 minutes to finish\ny_true = validation_set['type']\n\n# Results as 4 categories (NT, NF, ST, SF)\ny_pred_soft = y_pred.str.replace('I', '').str.replace('E','').str.replace('J','').str.replace('P','')\ny_true_soft = y_true.str.replace('I', '').str.replace('E','').str.replace('J','').str.replace('P','')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:50:11.534475Z","iopub.execute_input":"2021-10-27T18:50:11.535291Z","iopub.status.idle":"2021-10-27T18:57:23.204916Z","shell.execute_reply.started":"2021-10-27T18:50:11.535247Z","shell.execute_reply":"2021-10-27T18:57:23.204153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification reports\nprint(\"4 Classes\")\nprint(classification_report(y_true_soft, y_pred_soft))\n\nprint(\"\\n16 Classes\\n\")\nprint(classification_report(y_true, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:57:27.512402Z","iopub.execute_input":"2021-10-27T18:57:27.512724Z","iopub.status.idle":"2021-10-27T18:57:27.719261Z","shell.execute_reply.started":"2021-10-27T18:57:27.512691Z","shell.execute_reply":"2021-10-27T18:57:27.718421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = \"\"\"\nHey, they call me the Commander, I create plans and strategies for everything,\nI solve problems using highly optimized solutions, and I use my intuition\nto predict possible scenarios in the future, some people consider me as bossy,\nbut I'm not, recognized me?\n\"\"\"\npersonality, probability = run(sentence) # ENTJ\nprint(f\"Personality: {personality}\\nLikelihood: {probability}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:57:50.660174Z","iopub.execute_input":"2021-11-02T12:57:50.66046Z","iopub.status.idle":"2021-11-02T12:57:50.715483Z","shell.execute_reply.started":"2021-11-02T12:57:50.660428Z","shell.execute_reply":"2021-11-02T12:57:50.714637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = \"\"\"\nHey, they call me the Adventurer, I do artworks and sometimes play guitar,\nI enjoy spending time alone listening to music, I appreciate authenticity\nand honesty, I'm always connected to my feelings and alert of it,\nsome people consider as an artist, but I'm not, and I won't let them\ndefine what I am, regonized me?\n\"\"\"\npersonality, probability = run(sentence) # ISFP\nprint(f\"Personality: {personality}\\nLikelihood: {probability}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:58:13.113955Z","iopub.execute_input":"2021-11-02T12:58:13.114772Z","iopub.status.idle":"2021-11-02T12:58:13.174434Z","shell.execute_reply.started":"2021-11-02T12:58:13.114729Z","shell.execute_reply":"2021-11-02T12:58:13.173833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = \"\"\"\nHey guys, wanna hang out ? come on ..\nhiking out, flirting with girls, going to parties ..\nwhat's life without fun!\n\"\"\"\npersonality, probability = run(sentence) # ESxP\nprint(f\"Personality: {personality}\\nLikelihood: {probability}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:57:39.285256Z","iopub.execute_input":"2021-10-27T18:57:39.286437Z","iopub.status.idle":"2021-10-27T18:57:39.33596Z","shell.execute_reply.started":"2021-10-27T18:57:39.286373Z","shell.execute_reply":"2021-10-27T18:57:39.335302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = \"\"\"\nHey. .. .. .. what? .. .. ..\nokay I forgot. Hi, I'm the Logician, or at least that's what they call me besides 'the robot',\nI use my critical thinking skills to logically analyze everything,\nI spend a lot of my time thinking about solutions for problems that will never occur,\nreading articles, investigating theories, understanding concepts, it's all about my mind.\nI know I'm in a computer program being tested, I recognized you ..\n\"\"\"\npersonality, probability = run(sentence) # INTP\nprint(f\"Personality: {personality}\\nLikelihood: {probability}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:57:41.49455Z","iopub.execute_input":"2021-10-27T18:57:41.495489Z","iopub.status.idle":"2021-10-27T18:57:41.562607Z","shell.execute_reply.started":"2021-10-27T18:57:41.495441Z","shell.execute_reply":"2021-10-27T18:57:41.561519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}